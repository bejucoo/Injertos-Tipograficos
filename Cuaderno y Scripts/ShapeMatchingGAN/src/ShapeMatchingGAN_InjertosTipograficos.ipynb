{"cells":[{"cell_type":"markdown","metadata":{"id":"6qBPTzvN6zYP"},"source":["# **Injertos Tipogr√°ficos üà∏üåæ**\n","\n","Este es el cuaderno base que se utiliz√≥ durante el Laboratorio *Injertos Tipogr√°ficos*, proyecto ganador‚Äã ‚Äãde‚Äã ‚Äãla‚Äã ‚ÄãBeca‚Äã Plataforma Bogot√° en Arte, Ciencia y Tecnolog√≠a ‚Äã2021.\n","\n","Por favor, antes de empezar, **asegurarse de hacer una copia de los archivos de [esta carpeta](https://drive.google.com/drive/folders/1dU99WNiC8ytsxTVL_bN_8kKZ5SIf8lO_?usp=sharing) o hacer una copia de este cuaderno en su cuenta de Google Drive.**\n","\n","Si hace una copia de la carpeta, este cuaderno se encontrar√° dentro de /ShapeMatchingGAN/src.\n"]},{"cell_type":"markdown","metadata":{"id":"HjdgDQo5yfKu"},"source":["---\n","## Montar Drive\n","Todos los archivos que se utilizan para crear los injertos (im√°genes, modelos, scripts) estar√°n alojados en el drive de cada usuario. Para vincular Colab con Drive, es necesario ejecutar la siguiente celda:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3p7k0VfayweH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654485925669,"user_tz":300,"elapsed":21089,"user":{"displayName":"Pierre Puentes","userId":"08413786698885331197"}},"outputId":"c61dcc16-33a1-4734-c5b5-1ea70e04974d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"DwHMQmhTYFia"},"source":["## Importar carpeta **src**\n","\n","M√°s adelante se van a utilizar archivos que requieren importar la carpeta **src**, donde est√°n alojados. Est√° incluida en la carpeta que se pidi√≥ copiar al principio del cuaderno.\n","\n","**Copiar la ruta de la carpeta usando el explorador de archivos de la izquierda y pegarlo en la siguiente celda, en la l√≠nea que empieza con `sys.path.append`.**\n","\n","La ruta a la carpeta debe terminar en '/ShapeMatchingGAN/src'\n","\n","Por ejemplo: '/content/drive/MyDrive/S6_220521/ShapeMatchingGAN/src'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OjvdpF1owGTO"},"outputs":[],"source":["import sys\n","# Copiar ruta a la carpeta en la siguiente linea\n","sys.path.append('/content/drive/MyDrive/Maleza/S6_220521/ShapeMatchingGAN/src')"]},{"cell_type":"markdown","metadata":{"id":"nWr6wC-3HdNq"},"source":["---\n","# **Creaci√≥n de datasets**\n","\n","Un Injerto Tipogr√°fico se crea trasladando la forma y la textura de una imagen estilo a una letra usando la herramienta [Shape-MatchingGAN](https://williamyang1991.github.io/projects/ICCV2019/SMGAN.html). Para que SMGAN aprenda a trasladar estas caracter√≠sticas de una im√°gen a otra, hay que entrenarla con unos datasets espec√≠ficos.\n","\n","![injerto](https://i.imgur.com/SqZWpba.jpg)\n","\n","## ImageMagick\n","\n","Para crear los datasets necesarios se puede utilizar [ImageMagick](https://imagemagick.org/index.php), un software gratuito que permite crear, editar, componer y convertir im√°genes digitales. Se utiliza mediante comandos (lineas de texto), por ejemplo: `magick image.jpg image.png`\n","\n","El software tiene varios componentes entre ellos `magick`, `convert`, `montage`y `mirage`. En este cuaderno se utilizan algunos de ellos.\n","\n","Lo primero que se debe hacer es instalar IM ejecutando la siguiente celda:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sR7PUQBnHf4K"},"outputs":[],"source":["!sudo apt-get update && sudo apt-get upgrade && apt install imagemagick"]},{"cell_type":"markdown","metadata":{"id":"zdwlPGzsWH8e"},"source":["Luego se puede confirmar la versi√≥n de ImageMagick que est√° instalada:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xwmyH_xZHx2v"},"outputs":[],"source":["!convert -version"]},{"cell_type":"markdown","metadata":{"id":"AVFxn20BXHZ_"},"source":["## Base tipogr√°fica\n","El primer dataset que se crea es el de texto. SMGAN requiere aprender a reconocer la forma de letras u otros s√≠mbolos para poder trasladar las caracter√≠sticas de la imagen de estilo. El proceso detallado se encuentra en la secci√≥n *4.1 Bidirectional Structure Transfer (GS)* del [paper de SMGAN](https://arxiv.org/abs/1905.01354).\n","\n","  **Importante: Si ya se han creado las imagenes de texto anteriormente se puede pasar al paso** ***Aumento de dataset***, **asegur√°ndose que:**\n","\n","- **Las im√°genes NO tengan canal de transparencia. M√°s Informaci√≥n [aqu√≠](https://sking7.github.io/articles/66662475.html).**\n","- **Las im√°genes est√©n preferiblemente en formato .jpg.**\n","- **Las ima√°genes tengan el mismo tama√±o que la im√°gen de estilo.**\n","\n","El comando que nos permite crear una imagen con texto en blanco y negro es el siguiente:\n","\n","```\n","convert -gravity center -background \"rgb(0,0,0)\" -fill \"rgb(255,255,255)\" -define colorspace:auto-grayscale=off -type TrueColor -alpha off -size 500x500 -font \"ruta/a/la/fuente.ttf\" -pointsize 280 caption:Texto ruta/a/la_imagen.jpg\n","```\n","\n","- `convert` llama a la librer√≠a ImageMagick.\n","\n","- `-gravity center` obliga a centrar el texto dentro de la imagen.\n","\n","- `-background \"rgb(0,0,0)\"` establece un fondo de color negro.\n","\n","- `-define colorspace:auto-grayscale=off` y `-type TrueColor` obligan a que las im√°genes no est√©n en escala de grises. Esto tiene invonvenientes con los scripts de SMGAN.\n","\n","- `-alpha off` establece que las im√°genes no tengan transparencia.\n","\n","- `-size 500x500` establece el tama√±o de las im√°genes en 500 pixeles de ancho y de alto. **Importante: el tama√±o de estas im√°genes debe ser igual al tama√±o de la im√°gen de estilo.**\n","\n","- `-font \"ruta/a/la/fuente.ttf\"` establece que fuente usar.\n","\n","- `-pointsize 280` establece el tama√±o de la fuente.\n","\n","- `caption:Texto` establece el texto que se dibujar√°.\n","\n","- `ruta/a/la_imagen.jpg` establece a donde se guarda la imagen y el nombre del archivo.\n","\n","Luego de ejecutarlo, el resultado es el siguiente:\n","\n","![resultado](https://i.imgur.com/iC9F5k8.jpg)"]},{"cell_type":"markdown","metadata":{"id":"FVtfdLhC7Fds"},"source":["Como con otras GANs, es mejor utilizar una gran cantidad de im√°genes para su entrenamiento. En la carpeta /Glifos/base/original se encuentra el archivo `base_original.sh` que tiene un comando que repite el procedimiento anterior varias veces con las diferentes letras del abecedario. **Usando el explorador de la izquierda puede buscar el archivo y hacer doble click para editarlo y cambiar los ajustes.**\n","\n","```\n","array=(A B C)\n","for i in \"${array[@]}\"\n","do\n","\tconvert -gravity center -background \"rgb(0,0,0)\" -fill \"rgb(255,255,255)\" -define colorspace:auto-grayscale=off -type TrueColor -alpha off -size 500x500 -font \"ruta/a/la/fuente.ttf\" -pointsize 280 caption:$i ruta/a/las_imagenes/$i'.jpg'\n","done\n","echo \"${#array[@]} im√°genes creadas.\"\n","\n","```\n","\n","Con las siguientes celdas\n","\n","1. Se le indica a Colab que vaya a la carpeta de Drive que contiene el script **(cambiar la ruta a la carpeta de acuerdo a donde la haya guardado):**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bsG-QqsVSD0u"},"outputs":[],"source":["import os\n","%cd '/content/drive/MyDrive/S6_220521/Glifos/base/original'"]},{"cell_type":"markdown","source":["2. Se ejecuta el script"],"metadata":{"id":"jP-e408Fm5Vs"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"CpUCeECwQGOk"},"outputs":[],"source":["%%shell\n","bash '/content/drive/MyDrive/S6_220521/Glifos/base_original.sh'"]},{"cell_type":"markdown","metadata":{"id":"CaF3yiQDbAKW"},"source":["Este es un ejemplo de los resultados que se obtienen al ejecutar la celdas anteriores:\n","\n","![ejemplo_a](https://i.imgur.com/v6Uhy7y.jpg)"]},{"cell_type":"markdown","metadata":{"id":"4UEfZUn_Xqu0"},"source":["## Aumento de dataset\n","Para que el entrenamiento sea m√°s efectivo, se debe aumentar el dataset con im√°genes con diferentes transformaciones. Esto se hace con la libreria [Augmentor](https://github.com/mdbloice/Augmentor) de python. Las documentaci√≥n de las principales transformaciones se puede encontrar [aqu√≠](https://augmentor.readthedocs.io/en/master/userguide/mainfeatures.html).\n","\n","Lo primero que se debe hacer es instalar la librer√≠a:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PBh8jK1XWcW3"},"outputs":[],"source":["# Instalar la librer√≠a Augmentor\n","!pip install Augmentor"]},{"cell_type":"markdown","source":["Luego se aplican las transformaciones. Tener en cuenta los ajustes:\n","\n","- `carpeta_original` es donde se encuentran las im√°genes en blanco y negro creadas anteriormente.\n","- `carpeta_aumentada` es donde se guardar√°n las nuevas im√°genes transformadas.\n","- `cant_imagenes` es la cantidad de im√°genes que se va a crear.\n","- `rot_probability`, `rot_left` y `rot_right` definen que tan probable es que las im√°genes se roten y cu√°ntos grados en cada direcci√≥n.\n","- `zoom_probability`, `zoom_min` y `zoom_max` definen qu√© tan probable es que se cambie el tama√±o de las im√°genes y en qu√© cantidad.\n","- `flip_horizontal_probability` y `flip_vertical_probability` define qu√© tan probable es que las im√°genes sean volteadas horizontal y verticalmente (espejo)."],"metadata":{"id":"yB9PanVnuwjw"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"HKsla5_-Xgz1"},"outputs":[],"source":["# Importa la librer√≠a\n","import Augmentor\n","\n","# Rutas de las carpetas con las im√°genes originales y donde se guardan las aumentadas.\n","carpeta_original = \"/content/drive/MyDrive/S6_220521/Glifos/base/original\" #@param {type:\"string\"}\n","carpeta_aumentada = \"/content/drive/MyDrive/S6_220521/Glifos/base/original/augmentor\" #@param {type:\"string\"}\n","\n","# Cantidad de im√°genes a crear:\n","cant_imagenes =  520#@param {type : \"integer\"}\n","\n","# Variables para controlar las transformaciones\n","# Rotaci√≥n. Los valores de rot_left y rot_right se da en grados.\n","rot_probability = 0.5 #@param {type:\"slider\", min:0.1, max:1, step:0.1}\n","rot_left = 12 #@param {type:\"slider\", min:0, max:25, step:1}\n","rot_right = 12 #@param {type:\"slider\", min:0, max:25, step:1}\n","\n","# Zoom\n","zoom_probability = 0.5 #@param {type:\"slider\", min:0.1, max:1, step:0.1}\n","zoom_min = 0.3 #@param {type:\"slider\", min:0, max:2, step:0.1}\n","zoom_max = 1.8 #@param {type:\"slider\", min:0, max:2, step:0.1}\n","\n","# Reflejo:\n","flip_horizontal_probability = 0.5 #@param {type:\"slider\", min:0.1, max:1, step:0.1}\n","flip_vertical_probability = 0.5 #@param {type:\"slider\", min:0.1, max:1, step:0.1}\n","\n","# Iniciar la librer√≠a\n","p = Augmentor.Pipeline(carpeta_original, output_directory=carpeta_aumentada)\n","\n","# Opciones de las ransformaciones\n","p.rotate(probability=rot_probability, max_left_rotation=rot_left, max_right_rotation=rot_right)\n","p.zoom(probability=zoom_probability, min_factor=zoom_min, max_factor=zoom_max)\n","p.flip_left_right(probability=flip_horizontal_probability)\n","p.flip_top_bottom(probability=flip_vertical_probability)\n","\n","# Cantidad de im√°genes\n","p.sample(cant_imagenes)"]},{"cell_type":"markdown","metadata":{"id":"F2UAIMXCcQm4"},"source":["Al ejecutar el script quedar√°n guardadas im√°genes como la siguiente:\n","\n","![letra_aumentada](https://i.imgur.com/6llo3FO.png)"]},{"cell_type":"markdown","metadata":{"id":"thEWG63BaSX4"},"source":["## Im√°genes de distancia\n","\n","Para entrenar la red es necesario convertir las im√°genes blanco y negro a im√°genes basadas en distancia. Estas se crean al calcular la distancia entre los diferentes bordes que existen en la imagen. Seg√∫n [el repositorio](https://github.com/VITA-Group/ShapeMatchingGAN#testing-example) de SMGAN, las im√°genes basadas en distancia hacen que la red se ocupe mejor de las regiones saturadas.\n","\n","La siguiente celda genera estas versiones usando las im√°genes creadas en el paso anterior. \n","\n","- `carpeta_augmentor` es donde se guardaron las im√°genes transformadas con Augmentor.\n","- `carpeta_train` es donde se guardar√°n las nuevas im√°genes basadas en distancia.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hyM_sStmaYWP"},"outputs":[],"source":["# Importa las librerias necesarias\n","import os\n","import glob\n","import utils\n","\n","# Variable para numerar las im√°genes\n","image_num = 0\n","\n","# Rutas de las carpetas de augmentor y train\n","carpeta_augmentor = \"/content/drive/MyDrive/S6_220521/Glifos/base/original/augmentor\" #@param {type:\"string\"}\n","carpeta_train = \"/content/drive/MyDrive/S6_220521/Glifos/base/train\" #@param {type:\"string\"}\n","\n","# Indicar que se usen los archivos .jpg en la carpeta augmentor\n","carpeta_augmentor_files = carpeta_augmentor + \"/*.jpg\"\n","\n","# Crea las versiones basadas en distancia\n","for image in glob.glob(carpeta_augmentor_files):\n","    utils.text_image_preprocessing(image, carpeta_train + \"/\" + str(image_num) + \".png\")\n","    image_num += 1"]},{"cell_type":"markdown","metadata":{"id":"RprLloG0I9Pv"},"source":["Finalmente la siguiente celda re-nombra las im√°genes para que sigan el patr√≥n requerido por SMGAN: `0000.png, 0001.png, 0002.png, ...` **Importante: cambiar la ruta a la `carpeta_train` usada anteriormente en la l√≠nea que comienza con `os.chdir('')`**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c_wS3cSsNj75"},"outputs":[],"source":["# Importa las librer√≠as necesarias\n","import os\n","import glob\n","\n","# Ruta a la carpeta con las im√°genes creadas anteriormente. No olvidar cambiar.\n","os.chdir(r\"/content/drive/MyDrive/S6_220521/Glifos/base/train\")\n","for index, oldfile in enumerate(glob.glob(\"*.png\"), start=0):\n","    newfile = '{:04}.png'.format(index)\n","    os.rename (oldfile,newfile)"]},{"cell_type":"markdown","metadata":{"id":"njJcUCWWcvCF"},"source":["Este es el tipo de im√°genes finales que se usar√°n para entrenar la SMGAN:\n","\n","![distance](https://i.imgur.com/M2lstx4.png)"]},{"cell_type":"markdown","metadata":{"id":"7mC94WuoAyYI"},"source":["## **Im√°gen de estilo**\n","El segundo componente de los injertos es la im√°gen de estilo. De esta imagen se obtendr√° la forma y la textura de los Injertos. **Es necesario que previamente se haya escogido una imagen y escalado al mismo tama√±o de las im√°genes de estilo:**\n","\n","![original](https://i.imgur.com/Jxycvxa.png)\n","\n","y que se haya hecho una m√°scara en blanco y negro separando la planta y el fondo. Lo que se encuentre de blanco ser√° lo que se utilizar√° para deformar y texturizar las letras.\n","\n","![mask](https://i.imgur.com/2Oufmgg.png)\n","\n","Ambas im√°genes se deben guardar en la carpeta **Estilo**. En este caso solo se necesita una imagen por lo que el proceso se puede hacer usando Photoshop, GIMP o cualquier otro editor.\n","\n","Con las siguientes celdas\n","1. Se crea la versi√≥n basada en distancia de la imagen blanco y negro.\n","\n","  - `carpeta_estilo` es la ruta de la carpeta donde se guardaron las dos im√°genes.\n","  - `imagen_BN` es el nombre del archivo de las m√°scara en blanco y negro.\n","  - `imagen_DISTANCIA` es el nombre que recibir√° el archivo de la im√°gen basada en distancia."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F_zhjOcLxvmS"},"outputs":[],"source":["# Importar librerias\n","import utils\n","carpeta_estilo = \"/content/drive/MyDrive/S6_220521/Estilo\" #@param {type:\"string\"}\n","\n","# Nombre de las imagenes\n","imagen_BN = \"Muehlenbeckia_mask.jpg\" #@param {type:\"string\"}\n","imagen_DISTANCIA = \"Muehlenbeckia_concat.jpg\" #@param {type:\"string\"}\n","\n","entrada = carpeta_estilo + \"/\" + imagen_BN\n","salida = carpeta_estilo + \"/\" + imagen_DISTANCIA\n","\n","# Crear la imagen de distancia\n","utils.text_image_preprocessing(entrada, salida)"]},{"cell_type":"markdown","source":["2. Se le dice a Colab en donde guardar la imagen final."],"metadata":{"id":"peO5MYvSxNm-"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"mKP7joBDyzJv"},"outputs":[],"source":["# Importar la libreria os e ir a la carpeta de Estilo\n","import os\n","%cd '/content/drive/MyDrive/S6_220521/Estilo'"]},{"cell_type":"markdown","source":["3. Se crea una imagen compuesta por el estilo original y la imagen de distancia\n","\n","  - `montage` llama a la librer√≠a ImageMagick.\n","  - `-tile x1` establece que la imagen tenga solo una fila.\n","  - `-geometry 500x500` establece el tama√±o de cada imagen.\n","  - `background none` establece que la imagen no tenga fondo o marco."],"metadata":{"id":"r59EzHkhxPtV"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"TYxawotLyV12"},"outputs":[],"source":["!montage \"/content/drive/MyDrive/S6_220521/Estilo/Muehlenbeckia_distance.png\" \"/content/drive/MyDrive/S6_220521/Estilo/Muehlenbeckia_original.png\" -tile x1 -geometry 500x500 -background none Muehlenbeckia_concat.jpg"]},{"cell_type":"markdown","metadata":{"id":"-6yeGMAuNzeC"},"source":["Luego de ejecutar los comandos quedar√° una imagen como la siguiente. **Esta ser√° la imagen final de estilo:**\n","\n","![concat](https://i.imgur.com/pbkmUVk.png)"]},{"cell_type":"markdown","source":["---\n","# **ShapeMatchingGAN**"],"metadata":{"id":"5_RFrKQvry6N"}},{"cell_type":"markdown","metadata":{"id":"g_GwnmgsZGfS"},"source":["## Paso 1: Simplificaci√≥n de estructura\n","\n","Lo primero que hace SMGAN es simplificar la forma del estilo teniendo en cuenta la forma del texto.\n","\n","**El resultado de este proceso es un modelo llamado *GB*.**\n","\n","![paso_1](https://i.imgur.com/6lw1SwW.png)\n","\n","---\n","\n","Para ejecutar la siguiente celda tener encuenta los ajustes:\n","\n","- `archivo_GB` define la ruta a la carpeta y el nombre de archivo del modelo GB. El nombre del archivo debe finalizar con **-GB.cpkt**.\n","- `carpeta_train` define la ruta a la carpeta donde est√°n las im√°genes de texto (de distancia) creadas anteriormente.\n","- `num_train_images` define cu√°ntas de estas im√°genes hay.\n","- `carpeta_augment` define la ruta a la carpeta **augment** que se encuentra en /ShapeMatchingGAN/data/rawtext.\n","- `num_augment_images` define cu√°ntas de estas imagenes usar.\n","- `num_epochs` define el numero de iteraciones de entrenamiento.\n","- `batch_size` establece cuantas im√°genes agrupa en cada paso del proceso.\n","- `num_BTraining` establece el numero de pasos en cada iteraci√≥n. Durante el proceso este n√∫mero se dividir√° entre `batch_size`.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XLSkzstYyfLA"},"outputs":[],"source":["archivo_GB = \"/content/drive/MyDrive/S6_220521/Modelos/Muehlenbeckia-GB.cpkt\" #@param {type:\"string\"}\n","carpeta_train = \"/content/drive/MyDrive/S6_220521/Glifos/base/train\" #@param {type:\"string\"}\n","num_train_images =  50#@param {type : \"integer\"}\n","carpeta_augment = \"/content/drive/MyDrive/S6_220521/ShapeMatchingGAN/data/rawtext/augment\" #@param {type:\"string\"}\n","num_augment_images = 4 #@param {type:\"slider\", min:1, max:5, step:1}\n","\n","num_epochs = 3 #@param {type:\"slider\", min:1, max:5, step:1}\n","batch_size = 8 #@param {type:\"slider\", min:4, max:16, step:4}\n","num_BTraining = 6400 #@param {type:\"slider\", min:400, max:12800, step:400}\n","\n","from __future__ import print_function\n","import torch\n","from models import SketchModule\n","from utils import load_image, to_data, to_var, visualize, save_image, gaussian, weights_init\n","from utils import load_train_batchfnames, prepare_text_batch\n","import argparse\n","import os\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n","\n","opts = argparse.ArgumentParser()\n","opts.GB_nlayers = 6\n","opts.DB_nlayers = 5\n","opts.GB_nf = 32\n","opts.DB_nf = 32\n","opts.gpu = True\n","\n","opts.epochs = num_epochs\n","opts.save_GB_name = archivo_GB\n","opts.batchsize = batch_size\n","opts.text_path = carpeta_train\n","opts.augment_text_path = carpeta_augment\n","opts.text_datasize = num_train_images\n","opts.augment_text_datasize = num_augment_images\n","opts.Btraining_num = num_BTraining\n","\n","# create model\n","print('--- create model ---')\n","netSketch = SketchModule(opts.GB_nlayers, opts.DB_nlayers, opts.GB_nf, opts.DB_nf, opts.gpu)\n","if opts.gpu:\n","    netSketch.cuda()\n","netSketch.init_networks(weights_init)\n","netSketch.train()\n","\n","print('--- training ---')\n","for epoch in range(opts.epochs):\n","    itr = 0\n","    fnames = load_train_batchfnames(opts.text_path, opts.batchsize, \n","                                    opts.text_datasize, trainnum=opts.Btraining_num)\n","    fnames2 = load_train_batchfnames(opts.augment_text_path, opts.batchsize, \n","                                    opts.augment_text_datasize, trainnum=opts.Btraining_num)\n","    for ii in range(len(fnames)):\n","        fnames[ii][0:opts.batchsize//2-1] = fnames2[ii][0:opts.batchsize//2-1]\n","    for fname in fnames:\n","        itr += 1\n","        t = prepare_text_batch(fname, anglejitter=True)\n","        t = to_var(t) if opts.gpu else t\n","        losses = netSketch.one_pass(t, [l//4.-1. for l in range(0,9)])      \n","        print('Epoch [%d/%d][%03d/%03d]' %(epoch+1, opts.epochs,itr,len(fnames)), end=': ')\n","        print('LDadv: %+.3f, LGadv: %+.3f, Lrec: %+.3f'%(losses[0], losses[1], losses[2]))\n","\n","print('--- save ---')\n","# directory\n","torch.save(netSketch.state_dict(), opts.save_GB_name)"]},{"cell_type":"markdown","metadata":{"id":"PHMl5FfVH8NT"},"source":["### Pre-visualizaci√≥n del resultado de la simplificaci√≥n:\n","\n","**Importante:** Esta celda s√≥lo funciona si se ejecuta inmediatamente despu√©s del entrenamiento. Si se cierra el cuaderno de Colab y se vuelve a abrir, no ser√° posible pre-visualizar el resultado de la simplificaci√≥n. Sin embargo, si el entrenamiento finaliz√≥ y se guard√≥ el archivo _GB_ se puede continuar con el siguiente paso.\n","\n","En `imagen_estilo` se debe colocar la ruta a la im√°gen final de estilo que contiene la versi√≥n de distancia y la versi√≥n original."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g2IB0bdJyfLJ"},"outputs":[],"source":["imagen_estilo = \"/content/drive/MyDrive/S6_220521/Estilo/Muehlenbeckia_concat.jpg\" #@param {type:\"string\"}\n","\n","netSketch.eval()\n","I = load_image(imagen_estilo)\n","I = to_var(I[:,:,:,0:I.size(3)//2])\n","result = netSketch(I, -1.)\n","visualize(to_data(result[0]))"]},{"cell_type":"markdown","metadata":{"id":"hHS9Y-v4yfLM"},"source":["## Paso 2: Transferencia de estructura\n","\n","Lo siguiente que hace SMGAN es aprender a transferir la forma del estilo a las im√°genes de texto.\n","\n","**El resultado de este proceso es un modelo llamado *GS*.**\n","\n","![paso_2](https://i.imgur.com/WUmXkVs.png)\n","\n","---\n","\n","Para ejecutar la siguiente celda tener encuenta los ajustes:\n","\n","- `carpeta_modelos` define la ruta a la carpeta donde se guard√≥ el archivo GB del paso anterior y donde se guardar√°n los dem√°s modelos. **Se debe finalizar esta ruta con un /**\n","- `prefijo_modelos` define como se nombrar√°n los modelos. Se recomienda usar el mismo que se us√≥ para el archivo GB.\n","- `archivo_GB` define la ruta al archivo GB creado en el paso anterior.\n","- `carpeta_train` define la ruta a la carpeta donde est√°n las im√°genes de texto (de distancia).\n","- `num_train_images` define cu√°ntas de estas im√°genes hay.\n","- `imagen_estilo` establece la ruta a la imagen final de estilo que contiene la versi√≥n de distancia y la versi√≥n original.\n","- `step_1`, `step_2`, `step_3` y `step_4` definen el numero de iteraciones en cada momento del entrenamiento.\n","- `num_STraining` establece el numero de pasos en cada iteraci√≥n. Durante el proceso se dividir√° entre 8.\n","- `preserve_glyph` define si preservar la forma del glifo o no."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v6WuQuYYyfLN"},"outputs":[],"source":["carpeta_modelos = \"/content/drive/MyDrive/S6_220521/Modelos/\" #@param {type:\"string\"}\n","prefijo_modelos = \"Muehlenbeckia\" #@param {type:\"string\"}\n","archivo_GB = \"/content/drive/MyDrive/S6_220521/Modelos/Muehlenbeckia-GB.ckpt\" #@param {type:\"string\"}\n","carpeta_train = \"/content/drive/MyDrive/S6_220521/Glifos/base/train\" #@param {type:\"string\"}\n","num_train_images = 500 #@param {type : \"integer\"}\n","imagen_estilo = \"/content/drive/MyDrive/S6_220521/Estilo/Muehlenbeckia_concat.jpg\" #@param {type:\"string\"}\n","\n","step_1 = 15 #@param {type:\"slider\", min:1, max:30, step:1}\n","step_2 = 30 #@param {type:\"slider\", min:1, max:60, step:1}\n","step_3 = 45 #@param {type:\"slider\", min:1, max:90, step:1}\n","step_4 = 5 #@param {type:\"slider\", min:1, max:10, step:1}\n","\n","num_STraining = 1280 #@param {type:\"slider\", min:40, max:2560, step:40}\n","\n","preserve_glyph = True #@param {type:\"boolean\"}\n","\n","from __future__ import print_function\n","import torch\n","from models import SketchModule, ShapeMatchingGAN\n","from utils import load_image, to_data, to_var, visualize, save_image, gaussian, weights_init\n","from utils import load_train_batchfnames, prepare_text_batch, load_style_image_pair, cropping_training_batches\n","import random\n","import argparse\n","import os\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n","\n","opts = argparse.ArgumentParser()\n","# SMGAN\n","opts.GS_nlayers = 6\n","opts.DS_nlayers = 4\n","opts.GS_nf = 32\n","opts.DS_nf = 32\n","opts.GT_nlayers = 6\n","opts.DT_nlayers = 4\n","opts.GT_nf = 32\n","opts.DT_nf = 32\n","\n","# SketchModule\n","opts.GB_nlayers = 6\n","opts.DB_nlayers = 5\n","opts.GB_nf = 32\n","opts.DB_nf = 32\n","\n","opts.load_GB_name = archivo_GB\n","\n","# train \n","opts.gpu = True\n","\n","opts.step1_epochs = step_1\n","opts.step2_epochs = step_2\n","opts.step3_epochs = step_3\n","opts.step4_epochs = step_4\n","\n","opts.batchsize = 8\n","\n","opts.Straining_num = num_STraining\n","opts.scale_num = 4\n","opts.Sanglejitter = True\n","opts.subimg_size = 256\n","opts.glyph_preserve = preserve_glyph\n","opts.text_datasize = num_train_images\n","opts.text_path = carpeta_train\n","\n","# data and path\n","opts.save_path = carpeta_modelos\n","opts.save_name = prefijo_modelos\n","opts.style_name = imagen_estilo\n","\n","\n","# create model\n","print('--- create model ---')\n","netShapeM = ShapeMatchingGAN(opts.GS_nlayers, opts.DS_nlayers, opts.GS_nf, opts.DS_nf,\n","                 opts.GT_nlayers, opts.DT_nlayers, opts.GT_nf, opts.DT_nf, opts.gpu)\n","netSketch = SketchModule(opts.GB_nlayers, opts.DB_nlayers, opts.GB_nf, opts.DB_nf, opts.gpu)\n","\n","if opts.gpu:\n","    netShapeM.cuda()\n","    netSketch.cuda()\n","netShapeM.init_networks(weights_init)\n","netShapeM.train()\n","\n","netSketch.load_state_dict(torch.load(opts.load_GB_name))\n","netSketch.eval()\n","\n","print('--- training ---')\n","# load image pair\n","scales = [l*2.0/(opts.scale_num-1)-1 for l in range(opts.scale_num)]\n","Xl, X, _, Noise = load_style_image_pair(opts.style_name, scales, netSketch, opts.gpu)\n","Xl = [to_var(a) for a in Xl] if opts.gpu else Xl\n","X = to_var(X) if opts.gpu else X\n","Noise = to_var(Noise) if opts.gpu else Noise\n","for epoch in range(opts.step1_epochs):\n","    for i in range(opts.Straining_num//opts.batchsize):\n","        idx = opts.scale_num-1\n","        xl, x = cropping_training_batches(Xl[idx], X, Noise, opts.batchsize, \n","                                  opts.Sanglejitter, opts.subimg_size, opts.subimg_size)\n","        losses = netShapeM.structure_one_pass(x, xl, scales[idx])\n","        print('Step1, Epoch [%02d/%02d][%03d/%03d]' %(epoch+1, opts.step1_epochs, i+1, \n","                                                      opts.Straining_num//opts.batchsize), end=': ')\n","        print('LDadv: %+.3f, LGadv: %+.3f, Lrec: %+.3f, Lgly: %+.3f'%(losses[0], losses[1], losses[2], losses[3]))\n","netShapeM.G_S.myCopy()\n","for epoch in range(opts.step2_epochs):\n","    for i in range(opts.Straining_num//opts.batchsize):\n","        idx = random.choice([0, opts.scale_num-1])\n","        xl, x = cropping_training_batches(Xl[idx], X, Noise, opts.batchsize, \n","                                  opts.Sanglejitter, opts.subimg_size, opts.subimg_size)\n","        losses = netShapeM.structure_one_pass(x, xl, scales[idx])\n","        print('Step2, Epoch [%02d/%02d][%03d/%03d]' %(epoch+1, opts.step2_epochs, i+1, \n","                                                      opts.Straining_num//opts.batchsize), end=': ')\n","        print('LDadv: %+.3f, LGadv: %+.3f, Lrec: %+.3f, Lgly: %+.3f'%(losses[0], losses[1], losses[2], losses[3]))\n","for epoch in range(opts.step3_epochs):\n","    for i in range(opts.Straining_num//opts.batchsize):\n","        idx = random.choice(range(opts.scale_num))\n","        xl, x = cropping_training_batches(Xl[idx], X, Noise, opts.batchsize, \n","                                  opts.Sanglejitter, opts.subimg_size, opts.subimg_size)\n","        losses = netShapeM.structure_one_pass(x, xl, scales[idx])  \n","        print('Step3, Epoch [%02d/%02d][%03d/%03d]' %(epoch+1, opts.step3_epochs, i+1, \n","                                                      opts.Straining_num//opts.batchsize), end=': ')\n","        print('LDadv: %+.3f, LGadv: %+.3f, Lrec: %+.3f, Lgly: %+.3f'%(losses[0], losses[1], losses[2], losses[3]))\n","if opts.glyph_preserve:\n","    fnames = load_train_batchfnames(opts.text_path, opts.batchsize, \n","                                    opts.text_datasize, opts.Straining_num)\n","    for epoch in range(opts.step4_epochs):\n","        itr = 0\n","        for fname in fnames:\n","            itr += 1\n","            t = prepare_text_batch(fname, anglejitter=False)\n","            idx = random.choice(range(opts.scale_num))\n","            xl, x = cropping_training_batches(Xl[idx], X, Noise, opts.batchsize, \n","                                      opts.Sanglejitter, opts.subimg_size, opts.subimg_size)\n","            t = to_var(x) if opts.gpu else t\n","            losses = netShapeM.structure_one_pass(x, xl, scales[idx], t)  \n","            print('Step4, Epoch [%02d/%02d][%03d/%03d]' %(epoch+1, opts.step4_epochs, itr+1, \n","                                                      len(fnames)), end=': ')\n","            print('LDadv: %+.3f, LGadv: %+.3f, Lrec: %+.3f, Lgly: %+.3f'%(losses[0], losses[1], losses[2], losses[3])) \n","        \n","print('--- save ---')\n","# directory\n","netShapeM.save_structure_model(opts.save_path, opts.save_name)"]},{"cell_type":"markdown","metadata":{"id":"hV3ueSDGIw-c"},"source":["### Pre-visualizaci√≥n del resultado de la transferencia de estructura:\n","\n","**Importante:** Esta celda s√≥lo funciona si se ejecuta inmediatamente despu√©s del entrenamiento. Si se cierra el cuaderno de Colab y se vuelve a abrir, no ser√° posible pre-visualizar el resultado de la transferencia de estructura. Sin embargo, si el entrenamiento finaliz√≥ y se guard√≥ el archivo _GS_ se puede continuar con el siguiente paso.\n","\n","En `imagen_train` se debe colocar la ruta a una de las im√°genes de texto (de distancia)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E7k0MQfxyfLU"},"outputs":[],"source":["imagen_train = \"/content/drive/MyDrive/S6_220521/Glifos/base/train/0010.png\" #@param {type:\"string\"}\n","\n","netShapeM.eval()\n","I = load_image(imagen_train)\n","I = to_var(I[:,:,32:1000,32:1000])\n","I[:,0:1] = gaussian(I[:,0:1], stddev=0.2)\n","result = netShapeM.G_S(I, 1.0)\n","visualize(to_data(result[0]))"]},{"cell_type":"markdown","metadata":{"id":"Do4Cbsf-yfLV"},"source":["## Paso 3: Transferencia de textura\n","\n","Por √∫ltimo, SMGAN aprende a transferir la textura de la im√°gen de estilo a la im√°gen de texto.\n","\n","**El resultado de este proceso es un modelo llamado *GT*.**\n","\n","![paso_3](https://i.imgur.com/QG41tLG.png)\n","\n","---\n","\n","Para ejecutar la siguiente celda tener encuenta los ajustes:\n","\n","- `carpeta_modelos` define la ruta a la carpeta donde se guardaron los modelos en el paso anterior. **Finalizar esta ruta con un /**\n","- `prefijo_modelos` define como se nombrar√°n los modelos. Se recomienda usar el mismo que los archivos del paso anterior.\n","- `archivo_GS` define la ruta al archivo GS creado en el paso anterior.\n","- `carpeta_train` define la ruta a carpeta donde est√°n las im√°genes de texto (de distancia).\n","- `num_train_images` define cu√°ntas de estas im√°genes hay.\n","- `carpeta_augment` define la ruta a la carpeta **augment** que se encuentra en /ShapeMatchingGAN/data/rawtext.\n","- `num_augment_images` define cu√°ntas de estas imagenes usar.\n","- `imagen_estilo` establece la ruta a la imagen final de estilo que contiene la versi√≥n de distancia y la versi√≥n original.\n","- `step_1` define el numero de iteraciones de entrenamiento.\n","- `num_TTraining` establece el numero de pasos en cada iteraci√≥n. Durante el proceso se dividir√° entre 4."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kHaSfBNXyfLW","scrolled":true},"outputs":[],"source":["carpeta_modelos = \"/content/drive/MyDrive/S6_220521/Modelos/\" #@param {type:\"string\"}\n","prefijo_modelos = \"Muehlenbeckia\" #@param {type:\"string\"}\n","archivo_GS = \"/content/drive/MyDrive/S6_220521/Modelos/Muehlenbeckia-GS.ckpt\" #@param {type:\"string\"}\n","\n","carpeta_train = \"/content/drive/MyDrive/S6_220521/Glifos/base/train\" #@param {type:\"string\"}\n","num_train_images =  1024#@param {type : \"integer\"}\n","carpeta_augment = \"/content/drive/MyDrive/S6_220521/ShapeMatchingGAN/data/rawtext/augment\" #@param {type:\"string\"}\n","num_augment_images = 1 #@param {type:\"slider\", min:1, max:5, step:1}\n","\n","imagen_estilo = \"/content/drive/MyDrive/S6_220521/Estilo/Muehlenbeckia_concat.jpg\" #@param {type:\"string\"}\n","\n","step_1 = 40 #@param {type:\"slider\", min:1, max:80, step:1}\n","\n","num_TTraining = 600 #@param {type:\"slider\", min:4, max:1200, step:4}\n","\n","from __future__ import print_function\n","import torch\n","from models import SketchModule, ShapeMatchingGAN\n","from utils import load_image, to_data, to_var, visualize, save_image, gaussian, weights_init\n","from utils import load_train_batchfnames, prepare_text_batch, load_style_image_pair, cropping_training_batches\n","import random\n","from vgg import get_GRAM, VGGFeature\n","import torchvision.models as models\n","import argparse\n","import os\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n","\n","opts = argparse.ArgumentParser()\n","# SMGAN\n","opts.GS_nlayers = 6\n","opts.DS_nlayers = 4\n","opts.GS_nf = 32\n","opts.DS_nf = 32\n","opts.GT_nlayers = 6\n","opts.DT_nlayers = 4\n","opts.GT_nf = 32\n","opts.DT_nf = 32\n","\n","# train \n","opts.gpu = True\n","\n","opts.texture_step1_epochs = step_1\n","opts.texture_step2_epochs = 10\n","\n","opts.batchsize = 4\n","\n","opts.Ttraining_num = num_TTraining \n","\n","opts.Tanglejitter = True\n","opts.subimg_size = 256\n","opts.style_loss = False\n","\n","opts.text_path = carpeta_train\n","opts.text_datasize = num_train_images\n","opts.augment_text_path_path = carpeta_augment\n","opts.augment_text_datasize = num_augment_images\n","\n","\n","# data and path\n","opts.save_path = carpeta_modelos\n","opts.save_name = prefijo_modelos\n","opts.style_name = imagen_estilo\n","opts.load_GS_name = archivo_GS\n","\n","# create model\n","print('--- create model ---')\n","netShapeM = ShapeMatchingGAN(opts.GS_nlayers, opts.DS_nlayers, opts.GS_nf, opts.DS_nf,\n","                 opts.GT_nlayers, opts.DT_nlayers, opts.GT_nf, opts.DT_nf, opts.gpu)\n","\n","if opts.gpu:\n","    netShapeM.cuda()\n","netShapeM.init_networks(weights_init)\n","netShapeM.train()\n","\n","if opts.style_loss:\n","    netShapeM.G_S.load_state_dict(torch.load(opts.load_GS_name))  \n","    netShapeM.G_S.eval()\n","    VGGNet = models.vgg19(pretrained=True).features\n","    VGGfeatures = VGGFeature(VGGNet, opts.gpu)\n","    for param in VGGfeatures.parameters():\n","        param.requires_grad = False\n","    if opts.gpu:\n","        VGGfeatures.cuda()\n","    style_targets = get_GRAM(opts.style_name, VGGfeatures, opts.batchsize, opts.gpu)\n","    \n","print('--- training ---')\n","# load image pair\n","_, X, Y, Noise = load_style_image_pair(opts.style_name, gpu=opts.gpu)\n","Y = to_var(Y) if opts.gpu else Y\n","X = to_var(X) if opts.gpu else X\n","Noise = to_var(Noise) if opts.gpu else Noise\n","for epoch in range(opts.texture_step1_epochs):\n","    for i in range(opts.Ttraining_num//opts.batchsize):\n","        x, y = cropping_training_batches(X, Y, Noise, opts.batchsize, \n","                                  opts.Tanglejitter, opts.subimg_size, opts.subimg_size)\n","        losses = netShapeM.texture_one_pass(x, y)\n","        print('Step1, Epoch [%02d/%02d][%03d/%03d]' %(epoch+1, opts.texture_step1_epochs, i+1,\n","                                                     opts.Ttraining_num/opts.batchsize), end=': ')\n","        print('LDadv: %+.3f, LGadv: %+.3f, Lrec: %+.3f, Lsty: %+.3f'%(losses[0], losses[1], losses[2], losses[3])) \n","if opts.style_loss:\n","    fnames = load_train_batchfnames(opts.text_path, opts.batchsize, \n","                                    opts.text_datasize, trainnum=opts.Ttraining_num)\n","    for epoch in range(opts.texture_step2_epochs):\n","        itr = 0\n","        for fname in fnames:\n","            itr += 1\n","            t = prepare_text_batch(fname, anglejitter=False)\n","            x, y = cropping_training_batches(X, Y, Noise, opts.batchsize, \n","                                  opts.Tanglejitter, opts.subimg_size, opts.subimg_size)\n","            t = to_var(t) if opts.gpu else t\n","            losses = netShapeM.texture_one_pass(x, y, t, 0, VGGfeatures, style_targets)  \n","            print('Step2, Epoch [%02d/%02d][%03d/%03d]' %(epoch+1, opts.texture_step2_epochs, \n","                                                         itr, len(fnames)), end=': ')\n","            print('LDadv: %+.3f, LGadv: %+.3f, Lrec: %+.3f, Lsty: %+.3f'%(losses[0], losses[1], losses[2], losses[3])) \n","        \n","print('--- save ---')\n","# directory\n","netShapeM.save_texture_model(opts.save_path, opts.save_name)"]},{"cell_type":"markdown","metadata":{"id":"fmB5lVeUJDyJ"},"source":["### Pre-visualizaci√≥n del resultado de la transferencia de textura:\n","\n","**Importante:** Esta celda s√≥lo funciona si se ejecuta inmediatamente despu√©s del entrenamiento. Si se cierra el cuaderno de Colab y se vuelve a abrir, no ser√° posible pre-visualizar el resultado de la transferencia de textura. Sin embargo, si el entrenamiento finaliz√≥ y se guard√≥ el archivo _GT_ se puede continuar con el siguiente paso.\n","\n","- En `archivo_GS` se define la ruta al archivo *GS* creado en el paso 2.\n","- En `imagen_train` se establece la ruta a una de las im√°genes de texto (de distancia).\n","- `nombre_archivo_salida` define la ruta de la carpeta a donde se guardar√° la im√°gen de pre-visualizaci√≥n. **Se debe finalizar con /ElNombreDelArchivo.png**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bC-ruktSxQjj"},"outputs":[],"source":["archivo_GS = \"/content/drive/MyDrive/S6_220521/Modelos/Muehlenbeckia-GS.ckpt\" #@param {type:\"string\"}\n","imagen_train = \"/content/drive/MyDrive/S6_220521/Glifos/base/train/0050.png\" #@param {type:\"string\"}\n","nombre_archivo_salida = \"/content/drive/MyDrive/S6_220521/Results/0.png\" #@param {type:\"string\"}\n","\n","netShapeM.G_S.load_state_dict(torch.load(archivo_GS))  \n","netShapeM.eval()\n","I = load_image(imagen_train)\n","I = to_var(I[:,:,32:1000,32:1000])\n","result = netShapeM(I, 1)\n","visualize(to_data(result[0]))\n","save_image(to_data(result[0]), nombre_archivo_salida)"]},{"cell_type":"markdown","metadata":{"id":"4pEDdKguJN6x"},"source":["## Paso 4: Usar los modelos resultantes para generar los injertos:\n","\n","En la siguiente celda se usan los modelos resultantes para crear im√°genes con diferentes niveles de estilizaci√≥n y deformaci√≥n.\n","\n","- `!python3 ...` define la ruta al archivo `test_InjertosTipograficos.py` que se encuentra en la carpeta /ShapeMatchingGAN/src.\n","- `--text_name ...` define la imagen de texto que se quiere estilizar. Debe ser una im√°gen de distancia preferiblemente.\n","- `--scale` define el grado de estilizaci√≥n. Se puede usar `-3, -2 y -1`, siendo -3 el mayor grado de estilizaci√≥n.\n","- `--scale_step` define cuantos pasos hacer para llegar de 0 al valor que se use en `--scale`. Entre m√°s peque√±o el valor, m√°s pasos se har√°n y m√°s suave ser√° la transici√≥n. Se pueden usar valores entre 0.01 y 0.5.\n","\n","**Importante: entre mayor sea el n√∫mero en `--scale` y menor en `--scale_steps`, por ejemplo `-3 y 0.01`, el n√∫mero de im√°genes que se crean aumentar√°.**\n","\n","- `--structure_model ...` define la ruta al archivo **GS** creado en la transferencia de estructura.\n","- `--texture_model ...` define la ruta al archivo **GT** creado en la transferencia de textura.\n","- `--result_dir ...` define la ruta a la carpeta donde se guardar√°n las im√°genes.\n","- `--name ...` establece que nombre usar para cada imagen.\n","- `--gpu` le dice a Colab que utilice la Tarjeta de Video."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eLP7bN4w0Mg0"},"outputs":[],"source":["!python3 \"/content/drive/MyDrive/S6_220521/ShapeMatchingGAN/src/test_InjertosTipograficos.py\" \\\n","--text_name \"/content/drive/MyDrive/S6_220521/Glifos/base/train/0000.png\" \\\n","--scale -3 --scale_step 0.025 \\\n","--structure_model \"/content/drive/MyDrive/S6_220521/Modelos//Muehlenbeckia-GS.ckpt\" \\\n","--texture_model \"/content/drive/MyDrive/S6_220521/Modelos//Muehlenbeckia-GT.ckpt\" \\\n","--result_dir \"/content/drive/MyDrive/S6_220521/Modelos/Results/A\" --name \"Muehlenbeckia_A\" \\\n","--gpu"]},{"cell_type":"markdown","metadata":{"id":"CiGQl9UhJZbO"},"source":["\n","### Visualizaci√≥n de una de las im√°genes:\n","\n","Para ver alguna de las im√°genes creadas se puede utilizar la siguiente celda. Se debe cambiar la ruta a la imagen escogida."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DXLdIU2s1qbE"},"outputs":[],"source":["from IPython.display import Image\n","Image(\"/content/drive/MyDrive/S6_220521/Results/A/Muehlenbeckia_A_0.png\")"]},{"cell_type":"markdown","metadata":{"id":"_aOFz3FLhbLi"},"source":["### Generaci√≥n de video\n","\n","Si se quiere realizar una versi√≥n animada del injerto usando las im√°genes creadas en el paso 4, es posible realizarlo con la herramienta [ffmpeg](https://ffmpeg.org/). Es un software gratuiro que sirve para grabar, convertir, codificar y transmitir video. Como ImageMagick, se utiliza con comandos.\n","\n","Lo primero que se debe hacer es instalar la herramienta:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ge_b2AMchPcC"},"outputs":[],"source":["!sudo apt-get update && sudo apt-get upgrade && apt install ffmpeg"]},{"cell_type":"markdown","source":["Luego se debe ir a la carpeta que contiene las im√°genes y renombrarlas para que sigan un patr√≥n `0000.png, 0001.png, 0002.png ...` y no se generen saltos. **Se debe cambiar la ruta en la linea que comienza con `os.chdir()`.**"],"metadata":{"id":"HsV2pvmekryO"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"6gVOIH-rin2X"},"outputs":[],"source":["# Importa las librer√≠as necesarias\n","import os\n","import glob\n","\n","# Ruta a la carpeta con las im√°genes creadas anteriormente. No olvidar cambiar.\n","os.chdir(r\"/content/drive/MyDrive/S6_220521/Results/A\")\n","for index, oldfile in enumerate(glob.glob(\"*.png\"), start=0):\n","    newfile = '{:04}.png'.format(index)\n","    os.rename (oldfile,newfile)"]},{"cell_type":"markdown","source":["Finalmente con el siguiente comando se crea un video usando los frames de la carpeta.\n","\n","- `!ffmpeg` llama la herramienta.\n","- `loop 1` define que el video sea un loop.\n","- `-framerate 30` define los fotogramas por segundo.\n","- `pattern_type glob -i '*.png'` define que ffmpeg use todos los archivos con extensi√≥n .png.\n","- `-t 5` define la duraci√≥n del video en segundos.\n","- `-c:v libx264` define que se use el c√≥dec de video [h.264](https://trac.ffmpeg.org/wiki/Encode/H.264).\n","- `-pix_fmt yuv420p` define se use un [submuestreo](https://es.wikipedia.org/wiki/Submuestreo_de_crominancia) 4:2:0.\n","\n","- `out.mp4` define el nombre del archivo de salida."],"metadata":{"id":"J4idwEWkkyc3"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"tOwtHmmoi3O2"},"outputs":[],"source":["!ffmpeg -loop 1 -framerate 30 -pattern_type glob -i '*.png' -t 5 -c:v libx264 -pix_fmt yuv420p out.mp4"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"ShapeMatchingGAN_InjertosTipograficos.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
